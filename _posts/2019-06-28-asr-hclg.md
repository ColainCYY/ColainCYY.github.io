---
layout: post
title:  "kaldi中的解码图构建过程-可视化教程"
date:   2019-06-28 11:11:59 +0800
categories: kaldi asr
---

*注：本文翻译自 [Decoding graph construction in Kaldi: 
A visual walkthrough][origin-url], 并增加了一些解释。*

*建议读者阅读此本文前先阅读wfst speech decode的[论文][hbka-url]以及kaldi的解码图构建[文档][kaldi-decode-recipe]*

*草稿，需要校审*
 

专有名词
* Grammar fst(G) 语法模型，建模文本的概率，即N-gram语言模型,这切实是个FSA(acceptor),即输入和输出是一样的FST.
* Lexicon fst(L) 词典模型，建模音素序列到词序列之间的关系
* Context-Dependent fst(C）建模上下文相关音素序列到单音素序列的转换关系
* HMM Fst(H) 建模上下文相关音素HMM中的边序列到上下文相关音素序列的转换关系。
* self-loop 自跳转，fst中从当前state跳出仍回到该state的边
* bi-gram 二阶语言模型，当前词的条件概率只和前一个词有关 
* backoff 语言模型中，对于训练集中缺失的N阶gram，使用N-1阶的概率进行估计
* recipe kaldi里的完成某个任务整个可执行脚本
* cd-phone 上下文相关音素
* transition-id 解码fst的输入，每个transition-id对应一个(phone, HMM-state, pdf-id, transition-index)元组


最近我在使用kaldi时，识别错误率(WER)超过了40%，远高于我用的语言模型和声学模型应该得到的错误率。经过一番折腾，终于找到了原因 -- 我没有在lexicon fst(L)里加上自跳转(self-loop)。

在kaldi中为了使得Grammar FST(G)是determinizable的，在back-off边上使用了一个特殊的'#0'符号(也可以使用epsilon，但是这样G就是non-determinizable)，因此需要在Lexicon FST(L)加上一个自跳转使得compose L和G时可以经过G中输入是'#0'的边. 因为忘记加这个自跳转边,我的bigram G中的back-off边在compose时就被忽略了，使得语言模型没了backoff的能力，解码图里只存在训练集中见过的bigram的路径，从而导致了很高的错误率。而加上self-loop后，不用做其他任何改变，WER就下降到17%。


这个问题让我意识到自己对于解码图构建过程的细节理解的还不够，所以我决定花些时间认真研究一下。对于大词汇量的hclg而言，各级fst都太大，很难直观观察，我尝试过用GraphViz将解码图转为可视化图片，即使用的模型量级并不大（远小于LVCSR的规模），其占用的内存和cpu也非常巨大。另外，即使忽略机器性能问题，被优化过的HCLG WFST人类也几乎看不懂（至少远超我的理解能力）。所以本文我通过构建一个非常小规模的解码图来演示整个构建过程以帮助理解，这也是工程和科学中常用的方法。有一些很好的关于WFST解码的资料，包括著名的[hbka.pdf][hbka-url](WFST的圣经) 以及Dan Povey写的非常棒的kaldi解码图构建[recipe][kaldi-decode-recipe]，这篇blog可以作为这些资料的补充。

### 基本配置

本文使用规模很小的grammars和lexicon来演示完整HCLG构建过程. 语言模型方面，会unigram和bigram演示G FST的构建，而在逐级构建HCLG时则为了易懂使用unigram。下面是训练语言模型使用的语料

```
K. Cay
K. ache
Cay
```

对应的unigram语言模型是:

```
\data\
ngram 1=5

\1-grams:
-0.4259687 </s>
-99 <s>
-0.60206 Cay
-0.60206 K.
-0.9030899 ache

\end\
```

对应的Bigram model语言模型是:

```
\data\
ngram 1=5
ngram 2=6
\1-grams:
-0.4259687 </s>
-99 <s> -0.30103
-0.60206 Cay -0.2730013
-0.60206 K. -0.2730013
-0.9030899 ache -0.09691

\2-grams:
-0.60206 <s> Cay
-0.30103 <s> K.
-0.1760913 Cay </s>
-0.4771213 K. Cay
-0.4771213 K. ache
-0.30103 ache </s>
 
\end\
```

lexicon仅包含三个词，其中两个(Cay和K.)是同音词(homophone).
```
ache ey k
Cay k ey
K. k ey
```

为了使解码图尽可能简单易懂，尤其是其中用于将cd-phone变换为phone的fst C不要太复杂，总共的音素(phonemes)只有两个(ey和k).

本文用于生成解码图和pdf图片的脚本在这[script][script-url],其中也包含了该文章中展示的各fst的pdf，对于一些比较大的fst，可以直接打开pdf放大看. 使用'mkgraphs.sh'前，你需要先配置"KALDI_ROOT"指向机器上Kaldi的安装根目录。

### 语法FST的构建(G)
参考根据Kaldi中关于解码图创建的文档，下面是产生语法FST的命令，其中省略了移除OOV的步骤，因为这个例子里没有OOV(out-of-vocabulary,语言模型中的词不在lexicon里)的情况：

```
cat lm.arpa | \
    grep -v '<s> <s>' | \
    grep -v '</s> <s>' | \
    grep -v '</s> </s>' | \
    arpa2fst - | \     (step 1)
    fstprint | \
    eps2disambig.pl |\ (step 2)
    s2eps.pl | \       (step 3)
    fstcompile --isymbols=words.txt \
      --osymbols=words.txt  \
      --keep_isymbols=false --keep_osymbols=false | \
    fstrmepsilon > G.fst  (step 4)
```

最终的产生G的fst如下图:

![G_bi]({{ '/assets/images/hclg/G_bi.png' | relative_url }})
{: style="width: 640px;" class="center"}

下面我们一步一步来看这个脚本命令是如何处理bigram语言模型的。
#### step 1
首先，将语言模型中的非法的`<s>`和`</s>`的组合移除,因为这些组合会导致G FST是non-determinizable的。(译注：why？)。然后将结果送给arpa2fst，该工具将arpa转为binary格式的FST.

请注意，FST中的权重是对概率的自然对数取负，而ARPA文件中的数值是对概率取以10为底的对数。我们来细致的看一下arpa2fst产生的WFST。首先这个WFST有一个开始节点，表示一句话的开始(node 0),接着有三个节点分别表示`"ache"`, `"Cay"`, `"K."` 这三个词(分别是nodes 6, 4 and 5），另外，有一个back-off节点(node 1)和一个终止(final)节点(node 2).我们看一下`"<s> ache"`这个bigram词串在WFST中的路径，因为在训练语料中没有这个bigram，因此会存在back-off，`"<s> ache"`对应的路径为0到3，3到1，1到6. 0到3的权重是0;3到1的权重为0.69315，对应了`"<s>"`的back-off值(−ln(10−0.30103));1到6的权重为2.0794，这是`"ache"` (−ln(10−0.9030899))的unigram概率.
![G_bi_raw]({{ '/assets/images/hclg/G_bi_raw.png' | relative_url }})
{: style="width: 640px;" class="center"}
#### step 2
在step 2中，eps2disambig.pl脚本会将输入中的epsilon(backoff边上)转为特殊字符#0,从而使得fst是determinizable的。words.txt里应该有这个'#0'符号。(译注:)
![G_bi_eps2disambig]({{ '/assets/images/hclg/G_bi_eps2disambig.png' | relative_url }})
{: style="width: 640px;" class="center"}

#### step 3
Step 3中将"<s>"和"</s>"符号替换成epsilons。(译注:在WFST中开始和结束这个信息不需要用符号显示表达，WFST本身就蕴含了这个信息，即从开始节点出发和到达final节点)
![G_bi_s2eps]({{ '/assets/images/hclg/G_bi_s2eps.png' | relative_url }})
{: style="width: 640px;" class="center"}

#### step 4
Step 4 移除epsilon以简化FST(为何能移除？怎么移除？),得到最终的G fst
![G_bi]({{ '/assets/images/hclg/G_bi.png' | relative_url }})
{: style="width: 640px;" class="center"}

#### word symbol
WFST的符号表如下
```
<eps> 0
</s> 1
<s> 2
Cay 3
K. 4
ache 5 
#0 6
```

类似的对于unigram，其G FST如下，我们就不再单独分析。
![G_uni]({{ '/assets/images/hclg/G_uni.png' | relative_url }})
{: style="width: 640px;" class="center"}
由于HCLG的构建过程不受G的阶数的影响，为了HCLG的层次FST更简单易读，本文接下都使用unigram的G来展示HCLG的构建过程。如果你想了解bigram G构建出HCLG的过程，可以参考附件中的.pdf文件。

### 词典(Lexicon)FST的构建 (L)

 Kaldi中，lexicon FST 的准备过程是相对标准的.首先使用脚本`add_lex_disambig.pl`为每个同音字(这个例子里是"Cay" 和 "K.")，再发音之后添加一个单独的辅助符号进行区分，从而词典变成了:
```
ache ey k
Cay k ey #1
K. k ey #2
```

make_lexicon_fst.pl用于创建L FST. 这个脚本有四个参数
* 词典文件，其中包含了disambiguation符号(本例子里为#1，#2)
* 可选：silence音素的概率
* 可选：silence音素的符号
* 可选：silence的disambiguation符号（解释下)

```
make_lexicon_fst.pl lexicon_disambig.txt 0.5 sil '#'$ndisambig | \
   fstcompile --isymbols=lexgraphs/phones_disambig.txt \
    --osymbols=lmgraphs/words.txt \
    --keep_isymbols=false --keep_osymbols=false |\
   fstaddselfloops $phone_disambig_symbol $word_disambig_symbol | \
   fstarcsort --sort_type=olabel \
   > lexgraphs/L_disambig.fst
```

 make_lexicon_fst.pl 脚本会在每个词的发音开头和结束加入可选的silence音素（允许一个词的开头和结尾有silence），并且加入silence的disambiguation符号，一般为同音词已使用的最大disambiguation符号加1，本例中为#2+1=#3,只有在lexicon本身包含同音词需要disambig时才需要为silence引入一个disambiguation符号。具体解释见（？？？）

![L_disambig_without_silloop]({{ '/assets/images/hclg/L_disambig_without_silloop.png' | relative_url }})
{: style="width: 640px;" class="center"}

另外，记得G中用于backoff的#0辅助符号吗，我们的词典里并没有#0这个词，因此compose时G中输入为#0（要求L中输出时#0）这个路径都被丢弃了，这里的一个trick时加入一个`#0:#0`的self-loop边，:左边的#0是发音词典中引入的disambiguation符号，:右边的#0是G中的为了backoff引入的辅助符号.

![L_disambig]({{ '/assets/images/hclg/L_disambig.png' | relative_url }})
{: style="width: 640px;" class="center"}


带有disambiguation符号的的phone符号表如下
```
<eps> 0
ey 15
k 22
sil 42
#0 43
#1 44
#2 45
#3 46
```

一般phones.txt这个文件里symbol id从0开始连续的，注意这里不是0，1，2，3而是0，15，22，42，这是因为作者从一个真实声学模型的音素集里只抽取了两个音素，但是为了复用该声学模型音素集对应的H，仍保持了符号id. 另外可以看出，#x是从最大的id继续增加的.


### LG composition

L和G的 composition操作如下 
```
fsttablecompose L_disambig.fst G.fst |\
  fstdeterminizestar --use-log=true | \
  fstminimizeencoded  > LG.fst
```

这个命令里的`fsttablecompose/fstdeterminizestar/fstminimizeencoded`均为kaldi实现的fst操作，而不是openfst的命令，这个实现和openfst的标准compose/determinize/minimize有些微小的区别. 具体区别参考 [kaldi-fst][kaldi-fst-url]

![LG_uni]({{ '/assets/images/hclg/LG_uni.png' | relative_url }})
{: style="width: 640px;" class="center"}


### 上下文相关音素(context-dependent phones, cd-phones)FST (C)
*关于C FST以及CLG的处理设计`#-1`，`$`以及`logical/physical`的概念，是kaldi里理解起来比较麻烦的部分，本文仅简要介绍帮助初步理解，更深入理解需要看kaldi的文档/代码以及其他介绍*

在Kaldi中一般不会显示创建出单独的C FST再和LG compose，而是使用fstcomposecontext工具根据LG动态的生成CLG（注：因为穷举所有的cd-phones非常浪费，根据LG中的需要动态的创建用到的`cd-phones`会节省很多开销）。这里，处于演示的目的，现实的创建一个C FST。


```
fstmakecontextfst \
 --read-disambig-syms=disambig_phones.list \\
 --write-disambig-syms=disambig_ilabels.list \
 $phones $subseq_sym ilabels |\
 fstarcsort --sort_type=olabel > C.fst
```

创建的上下文相关的FST如下（C, 将`cd-phone`转换为上下文无关音素的FST）

![C]({{ '/assets/images/hclg/C.png' | relative_url }})
{: style="width: 640px;" class="center"}

该FST中，每个state都有一些自跳转，处理L中引入的辅助符号#X.

C FST的输入符号是triphone的id（这里已经把id转换为对应的可读符号/left-ctx/phone/right-ctx）, 实际上，kaldi用一个ilabel_info数据结构来存储C fst的输入符号的信息。ilabel_info是一个成员是数组的数组，数组里的每个元素记录一个C fst的输入符号信息。

举个例子，若triphone "a/b/c"在C中的symbol id是10(id从0开始)，则ilabel_info中的第11个元素存储了"a/b/c"的完整上下文信息，若a，b，c在L中的id分别为10，11，12，则该元素存储的信息为[10 11 20].

ilabel_info中还会存储#X符号，但是会将其在L中的id取负，如在L中#1的id是44，则在C中的input也会有一个对应的#1符号，其存储为[-44],之所以用符号，是为了方便直接判断当前是不是辅助符号。

以(N=3,P=1)为例每个边的格式为a/b/c:c，输入是a/b/c，即当前音素是b，左边上下文是a，右边上下文音素是c，要注意的是，边上输出不是当前音素b，而是下一个音素c.这就带来两个问题：

1. 假设某个词发音是a b c,对于词的第一个音素，a其三音素为`<eps>/a/b`,对应的边为`<eps>/a/b：b`，这时输出是b，那输出的a的边应该是什么样的，可以是`<eps>/<eps>/a`，而在kaldi中统一用#-1表示输入是空的，所以ilabel_info还存储了符号#-1，用于表示从初始状态开始先接受空输入产生音素。在start状态后会有(N-P-1)个#-1输入，才进入到第一个正常的`cd-phone`输入的边。

2. 当前上下文音素是a/b/c时输出了c，但是如果到了句子末尾，接下来的当前音素是`b/c/<eps>`应该输出什么呢？可以输出`<eps>`,但kaldi为C FST引入了一个专用符号$，从而使的C是output deterministic的，在和LG compose时更加高效。在final状态前会有(N-P-1)个$输出。

既然在C中加入了$这个输出，LG中也需要加入输入为$的边。使用Kaldi的工具fstaddsubsequentialloop为LG进行修改。
```
fstaddsubsequentialloop ${subseq_sym} cascade/LG_uni.fst > cdgraphs/LG_uni_subseq.fst
```
可以看到，每个LG中的final状态用"$:ϵ"边连接到一个带self-loop边的新的final状态上。有self-loop是为了处理C中连续(N-P-1)个"$"输出。

![LG_uni_subseq]({{ '/assets/images/hclg/LG_uni_subseq.png' | relative_url }})
{: style="width: 640px;" class="center"}



### CLG cascade

C/LG compose的脚本如下，过程和L/G compose 一样
```
fsttablecompose cdgraphs/C.fst cdgraphs/LG_uni_subseq.fst |\
  fstdeterminizestar --use-log=true |\
  fstminimizeencoded \
  > cascade/CLG_uni.fst
```
得到的CLG fst如下

![CLG_uni]({{ '/assets/images/hclg/CLG_uni.png' | relative_url }})
{: style="width: 640px;" class="center"}


对于CLG FST，我们可以使用一个FST将输入`cd-phone`进一步优化，减小`cd-phone`的个数。

注意，kaldi为了减小`cd-phone`的个数，一般使用决策树绑定，kaldi的决策数绑定支持将HMM中arc或者state的绑定，我们只讨论arc的绑定，绑定后的arc称为senon。加入某些`cd-phone` topo内对应的arc都绑定到同样的senone上，这些`cd-phone`（logical `cd-phone`）对应的同一个physical `cd-phone`，kaldi会随便在同一组logical `cd-phone`中选一个作为其phsical `cd-phone`的id。目前CLG中的输入可以认为是logical `cd-phone`，即所有可能组合的音素，根据决策树绑定，进一步减小输入。

可以构建一个fst，将physical`cd-phone`映射为logical`cd-phone`，

```
make-ilabel-transducer --write-disambig-syms=cdgraphs/disambig_ilabels_remapped.list\
 cdgraphs/ilabels $tree $model cdgraphs/ilabels.remapped \
 > cdgraphs/ilabel_map.fst
```

ilabel_map.fst是physical到logical的映射，如下图

![ilabel_map]({{ '/assets/images/hclg/ilabel_map.png' | relative_url }})
{: style="width: 640px;" class="center"}

将该fst和CLG fst compose，即可得到减小后的输入为physical `cd-phone`的CLG了。通过增加这个physical到logical的映射，unigram CLG的状态从24降到17，边从38降到26


![CLG_uni_reduced]({{ '/assets/images/hclg/CLG_uni_reduced.png' | relative_url }})
{: style="width: 640px;" class="center"}

kaldi中，把sil当作是上下文无关的音素，所有的`x/sil/y`都绑定到同一个`physical cd-phone`上，可以在该fst里看到这个映射。另外，我们的例子中，有一条边是`<eps>/ey/<eps>:ey/ey/<eps>`，表示对于音素'ey',若其左边是'ey',右边是`'<eps>'`,等价于左边是`'<eps>'`右边是`'<eps>'`.你可以用kaldi的draw-tree工具把tree中的信息输出，`"<eps>/ey/<eps>"`和`"ey/ey/<eps>"`的HMM中的PDF是一样的。


### H FST

H fst的功能是把`transition-id`序列映射到`cd-phone`序列. kaidi中，`一个cd-phone的当前phone，cd-phone的一个state，state上的一条边，以及其对应的pdf`有一个唯一标识`transition-id`.最终解码fst的输入不是pdf-id而是`transition-id`. `H fst`和`L fst`看起来很类似.

![Ha]({{ '/assets/images/hclg/Ha.png' | relative_url }})
{: style="width: 640px;" class="center"}


这个fst从一个start节点（同时也是final节点，这个fst是个closure）开始，进入到各个cd-phone的HMM。每个physical cd-phone输出对应一个hmm state的序列的输入（kaldi中其实是transition id序列）。注意并没有一个输出是`"ey/ey/<eps>"`的序列，因为`"ey/ey/<eps>"`是一个logical cd-phone，其physical cd-phone 是`"<eps>/ey/<eps>"`. 另外，start节点上还有一些自跳转用于处理C fst里引入的辅助符号，如`"#-1:#-1"`

这个FST的输入标签是我用一个自己写的工具[fstmaketidsyms][fstmaketidsyms-url]打印出来，这个标签展示了一个transition-id包含的四个信息（下划线分割），包括对应的cd-phone的对应的phone，cd-phone的中的HMM state，pdf的id以及该state上的对应的出度边的在该state上的index. 例如"k_1_739_1"表示该transition-id对应了音素k拓扑的一个state上的第1个出度边，其绑定到的pdf-id是739.（音素k的不同的cd-phone，同样位置的边上的pdf可能会绑定到不同的pdf上）
注意这个fst里没有包含hmm的自跳转，所以这个是Ha fst而不是H fst.当HCLG compose完了在加入HMM-self.

### HCLG fst

下面命令用于创建完整的HCLG（不包含HMM中的状态上的自跳转边）
```
fsttablecompose Ha.fst CLG_reduced.fst | \
   fstdeterminizestar --use-log=true | \
   fstrmsymbols disambig_tstate.list | \
   fstrmepslocal  | fstminimizeencoded \
   > HCLGa.fst
```

Ha fst和CLG fst(加入了physical到logical的mapping)进行compose， determinize操作， 然后将辅助符号(#n,compose和determinze之后这些辅助符号就没用了)用epsilons替代，然后再做minimize.


下图是输出结果，其中输入符号和上面Ha的产生方式一样，也是用[fstmaketidsyms][fstmaketidsyms-url]工具产生。



![HCLGa_uni]({{ '/assets/images/hclg/HCLGa_uni.png' | relative_url }})
{: style="width: 640px;" class="center"}


然后我们加上HMM里的自跳转边。
```
add-self-loops --self-loop-scale=0.1 \
    --reorder=true $model < HCLGa.fst > HCLG.fst
```

add-self-loops在加入self-loop时，会根据self-loop-scale参数调整概率（细节见kaldi文档）并且会对transition重排序(reorder),这个重排序操作使得对于每一帧特征，不需要计算两次同样的声学模型得分（对于通常的Bakis从左到右的HMM拓扑），从而可以使得解码过程更快。最终HCLG的解码涂伟


![HCLG_uni]({{ '/assets/images/hclg/HCLG_uni.png' | relative_url }})
{: style="width: 640px;" class="center"}

基本上就这些了，感谢阅读。



[origin-url]: https://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html

[hbka-url]: https://cs.nyu.edu/~mohri/pub/hbka.pdf
[kaldi-decode-recipe]: http://kaldi-asr.org/doc/graph_recipe_test.html

[script-url]: https://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html

[kaldi-fst-url]: http://kaldi-asr.org/doc/fst_algo.html

[fstmaketidsyms-url]:https://bitbucket.org/vdp/kaldi-rm1-mod/src/4fb1791d1210/cxx/fstmaketidsyms/fstmaketidsyms.cc